import os
import requests
from datetime import datetime, timedelta
from dateutil import parser
import re

# Configuration
api_key = os.getenv('DEEPSEEK_API_KEY')
github_token = os.getenv('GITHUB_TOKEN')
is_manual = os.getenv('IS_MANUAL_TRIGGER', 'false').lower() == 'true'
days_to_cover = int(os.getenv('DAYS_TO_COVER', '1'))
additional_repos_str = os.getenv('ADDITIONAL_REPOS', '')
additional_repos = [repo.strip() for repo in additional_repos_str.split(',') if repo.strip()]

# Date setup
today = datetime.utcnow().date()
since_date = today - timedelta(days=days_to_cover)

print(f"Generating reports for period: {since_date} to {today}")
print(f"Manual trigger: {is_manual}")
print(f"Additional repositories to process: {additional_repos}")

# GitHub API headers
github_headers = {
    "Authorization": f"token {github_token}",
    "Accept": "application/vnd.github.v3+json"
}

def generate_timestamp():
    """Generate timestamp for file naming"""
    return datetime.now().strftime("%H%M%S")

def get_commits(repo, since, until):
    """Fetch commits for a given repository"""
    try:
        commits_url = f"https://api.github.com/repos/{repo}/commits"
        params = {
            "since": since.isoformat(),
            "until": until.isoformat()
        }
        
        print(f"Fetching commits from: {commits_url}")
        response = requests.get(commits_url, headers=github_headers, params=params)
        print(f"GitHub API response status: {response.status_code}")
        
        if response.status_code != 200:
            print(f"Error response: {response.text}")
            return None
        
        commits = response.json()
        
        if not isinstance(commits, list):
            print(f"Error fetching commits for {repo}: {commits}")
            return None
        
        print(f"Found {len(commits)} commits for {repo}")
        return commits
        
    except Exception as e:
        print(f"Exception when fetching commits for {repo}: {str(e)}")
        return None

def process_commits(commits, repo):
    """Process commits and generate commit messages"""
    if not commits:
        return []
    
    commit_messages = []
    
    for commit in commits:
        try:
            if isinstance(commit, dict):
                sha = commit['sha']
                author = commit['commit']['author']['name']
                message = commit['commit']['message']
                
                print(f"Processing commit: {sha[:8]}...")
                
                # Get commit diff
                diff_url = f"https://api.github.com/repos/{repo}/commits/{sha}"
                diff_response = requests.get(diff_url, headers=github_headers)
                
                if diff_response.status_code == 200:
                    diff_data = diff_response.json()
                    files_changed = diff_data.get('files', [])
                    
                    file_changes = []
                    for file in files_changed:
                        filename = file['filename']
                        additions = file['additions']
                        deletions = file['deletions']
                        file_changes.append(f"{filename} (+{additions}/-{deletions})")
                    
                    commit_messages.append(
                        f"Repository: {repo}\n"
                        f"SHA: {sha}\n"
                        f"Author: {author}\n"
                        f"Message: {message}\n"
                        f"Files changed: {', '.join(file_changes) if file_changes else 'No files info'}\n"
                    )
                else:
                    print(f"Failed to get diff for commit {sha}: {diff_response.status_code}")
                    # å³ä½¿è·å–diffå¤±è´¥ï¼Œä¹Ÿä¿å­˜åŸºæœ¬commitä¿¡æ¯
                    commit_messages.append(
                        f"Repository: {repo}\n"
                        f"SHA: {sha}\n"
                        f"Author: {author}\n"
                        f"Message: {message}\n"
                        f"Files changed: Unable to fetch diff\n"
                    )
                    
        except Exception as e:
            print(f"Error processing commit: {str(e)}")
            continue
    
    print(f"Processed {len(commit_messages)} commit messages")
    return commit_messages

def generate_report(commits_text, repo):
    """Generate report using DeepSeek API"""
    try:
        # æ ¼å¼åŒ–æ—¥æœŸèŒƒå›´
        date_range = f"{since_date.strftime('%Y-%m-%d')}è‡³{today.strftime('%Y-%m-%d')}"
        
        prompt = (
            "ä½œä¸ºæŠ€æœ¯æ–‡æ¡£å·¥ç¨‹å¸ˆï¼Œè¯·æ ¹æ®ä»¥ä¸‹Gitæäº¤è®°å½•ç”Ÿæˆä¸“ä¸šå¼€å‘æŠ¥å‘Šã€‚\n\n"
            "è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹æ ¼å¼è¾“å‡ºæŠ¥å‘Šï¼š\n\n"
            f"## [{date_range}] å¼€å‘æŠ¥å‘Š\n\n"
            "### ğŸš€ æ–°åŠŸèƒ½å¼€å‘\n"
            "- æè¿°æ–°å¢çš„åŠŸèƒ½ç‰¹æ€§\n"
            "  - æ¶‰åŠæ–‡ä»¶ï¼šç›¸å…³æ–‡ä»¶åˆ—è¡¨\n"
            "  - æäº¤è®°å½•ï¼šSHAç®€ç \n\n"
            "### ğŸ› é—®é¢˜ä¿®å¤\n"
            "- æè¿°ä¿®å¤çš„é—®é¢˜\n"
            "  - é—®é¢˜ç±»å‹ï¼šbug/æ€§èƒ½/å®‰å…¨ç­‰\n"
            "  - å½±å“èŒƒå›´ï¼šæè¿°å½±å“\n"
            "  - æäº¤è®°å½•ï¼šSHAç®€ç \n\n"
            "### ğŸ”§ ä»£ç ä¼˜åŒ–\n"
            "- æè¿°ä»£ç æ”¹è¿›å’Œé‡æ„\n"
            "  - ä¼˜åŒ–ç±»å‹ï¼šæ€§èƒ½/å¯è¯»æ€§/æ¶æ„ç­‰\n"
            "  - æäº¤è®°å½•ï¼šSHAç®€ç \n\n"
            "### ğŸ“¦ ä¾èµ–æ›´æ–°\n"
            "- æè¿°ä¾èµ–åº“çš„æ›´æ–°\n"
            "  - æ›´æ–°å†…å®¹ï¼šç‰ˆæœ¬å˜åŒ–\n"
            "  - æäº¤è®°å½•ï¼šSHAç®€ç \n\n"
            "### ğŸ“ æ–‡æ¡£æ›´æ–°\n"
            "- æè¿°æ–‡æ¡£ç›¸å…³çš„æ›´æ–°\n"
            "  - æ›´æ–°å†…å®¹ï¼šæ–°å¢/ä¿®æ”¹çš„æ–‡æ¡£\n"
            "  - æäº¤è®°å½•ï¼šSHAç®€ç \n\n"
            "### âš ï¸ é‡è¦æé†’\n"
            "- éœ€è¦ç‰¹åˆ«æ³¨æ„çš„å˜æ›´ï¼ˆå¦‚ç ´åæ€§å˜æ›´ï¼‰\n"
            "- éƒ¨ç½²æ—¶éœ€è¦çš„ç‰¹æ®Šæ“ä½œ\n\n"
            "**åˆ†æè¦æ±‚ï¼š**\n"
            "1. æ ¹æ®æäº¤ä¿¡æ¯æ™ºèƒ½åˆ†ç±»åˆ°å¯¹åº”ç« èŠ‚\n"
            "2. æå–å…³é”®æŠ€æœ¯ä¿¡æ¯å’Œå½±å“èŒƒå›´\n"
            "3. å¦‚æœæŸä¸ªåˆ†ç±»æ²¡æœ‰ç›¸å…³æäº¤ï¼Œå¯ä»¥çœç•¥è¯¥ç« èŠ‚\n"
            "4. ä¿æŒä¸“ä¸šå’Œç®€æ´çš„æè¿°é£æ ¼\n"
            "5. SHAç åªæ˜¾ç¤ºå‰8ä½\n\n"
            "ä»¥ä¸‹æ˜¯æäº¤è®°å½•ï¼š\n\n"
            f"{commits_text}"
        )

        # Call DeepSeek API
        deepseek_url = "https://api.deepseek.com/chat/completions"
        headers = {
            "Authorization": f"Bearer {api_key}",
            "Content-Type": "application/json"
        }
        data = {
            "model": "deepseek-chat",
            "messages": [
                {"role": "user", "content": prompt}
            ],
            "temperature": 0,
            "stream": False
        }

        print(f"å‡†å¤‡è°ƒç”¨ DeepSeek APIï¼Œå†…å®¹é•¿åº¦: {len(prompt)} å­—ç¬¦")
        response = requests.post(deepseek_url, headers=headers, json=data)
        print(f"DeepSeek API å“åº”çŠ¶æ€ç : {response.status_code}")
        
        if response.status_code != 200:
            print(f"DeepSeek API é”™è¯¯å“åº”: {response.text}")
            return f"APIè°ƒç”¨å¤±è´¥ï¼Œç”ŸæˆåŸºç¡€æŠ¥å‘Š:\n\n{commits_text}"
        
        result = response.json()
        
        if 'choices' not in result or not result['choices']:
            print(f"DeepSeek API å“åº”æ ¼å¼å¼‚å¸¸: {result}")
            return f"APIå“åº”æ ¼å¼å¼‚å¸¸ï¼Œç”ŸæˆåŸºç¡€æŠ¥å‘Š:\n\n{commits_text}"
        
        return result['choices'][0]['message']['content']
        
    except Exception as e:
        print(f"ç”ŸæˆæŠ¥å‘Šæ—¶å‘ç”Ÿå¼‚å¸¸: {str(e)}")
        return f"æŠ¥å‘Šç”Ÿæˆå¼‚å¸¸ï¼Œç”ŸæˆåŸºç¡€æŠ¥å‘Š:\n\n{commits_text}"

def save_report(content, repo_name):
    """Save report to a markdown file"""
    try:
        # Create logs directory if not exists
        os.makedirs('logs', exist_ok=True)
        
        # Create subdirectory for this run
        run_dir = f"logs/{today.isoformat()}"
        os.makedirs(run_dir, exist_ok=True)
        
        # Generate filename with timestamp
        timestamp = generate_timestamp()
        filename = f"{run_dir}/{timestamp}_{repo_name.replace('/', '_')}.md"
        
        print(f"å‡†å¤‡ä¿å­˜æŠ¥å‘Šï¼Œå†…å®¹é•¿åº¦: {len(content)} å­—ç¬¦")
        print(f"ç›®æ ‡è·¯å¾„: {filename}")
        
        with open(filename, 'w', encoding='utf-8') as f:
            f.write(content)
        
        print(f"Report saved to: {filename}")
        return filename
        
    except Exception as e:
        print(f"ä¿å­˜æŠ¥å‘Šæ—¶å‘ç”Ÿå¼‚å¸¸: {str(e)}")
        return None

def update_readme(generated_reports):
    """Update README.md with links to generated reports"""
    try:
        readme_path = "README.md"
        
        # Read existing README or create new one
        if os.path.exists(readme_path):
            with open(readme_path, 'r', encoding='utf-8') as f:
                content = f.read()
        else:
            content = "# Daily Development Reports\n\n"
        
        # è·å–ä»Šå¤©æ—¥æœŸçš„æ‰€æœ‰æŠ¥å‘Šæ–‡ä»¶
        date_str = today.strftime('%Y-%m-%d')
        run_dir = f"logs/{date_str}"
        
        all_today_reports = []
        if os.path.exists(run_dir):
            # éå†ä»Šå¤©çš„ç›®å½•ï¼Œè·å–æ‰€æœ‰æŠ¥å‘Šæ–‡ä»¶
            for filename in os.listdir(run_dir):
                if filename.endswith('.md'):
                    file_path = f"{run_dir}/{filename}"
                    all_today_reports.append(file_path)
        
        # æ·»åŠ æœ¬æ¬¡ç”Ÿæˆçš„æŠ¥å‘Š
        for report_path in generated_reports:
            if report_path not in all_today_reports:
                all_today_reports.append(report_path)
        
        # æŒ‰æ–‡ä»¶åä¸­çš„æ—¶é—´æˆ³æ’åºï¼ˆé™åºï¼Œæ–°çš„åœ¨å‰ï¼‰
        def extract_timestamp(file_path):
            """ä»æ–‡ä»¶è·¯å¾„ä¸­æå–æ—¶é—´æˆ³"""
            filename = os.path.basename(file_path)
            # æ–‡ä»¶åæ ¼å¼: HHMMSS_repo_name.md
            timestamp_match = re.match(r'^(\d{6})_', filename)
            if timestamp_match:
                return timestamp_match.group(1)
            return "000000"  # å¦‚æœæ²¡æœ‰åŒ¹é…åˆ°æ—¶é—´æˆ³ï¼Œç»™ä¸ªé»˜è®¤å€¼
        
        all_today_reports.sort(key=extract_timestamp, reverse=True)
        
        # å‡†å¤‡ä»Šå¤©çš„æ¡ç›®
        new_entry = f"\n## {date_str}\n\n"
        for report_path in all_today_reports:
            filename = os.path.basename(report_path)
            # æå–æ—¶é—´æˆ³ç”¨äºæ˜¾ç¤º
            timestamp = extract_timestamp(report_path)
            formatted_time = f"{timestamp[:2]}:{timestamp[2:4]}:{timestamp[4:6]}"
            
            # æå–ä»“åº“åï¼ˆå»æ‰æ—¶é—´æˆ³å‰ç¼€å’Œ.mdåç¼€ï¼‰
            repo_name = filename
            if re.match(r'^\d{6}_', filename):
                repo_name = filename[7:]  # å»æ‰ "HHMMSS_" å‰ç¼€
            if repo_name.endswith('.md'):
                repo_name = repo_name[:-3]  # å»æ‰ ".md" åç¼€
            
            new_entry += f"- [{formatted_time}] [{repo_name}]({report_path})\n"
        
        new_entry += "\n"
        
        # æ£€æŸ¥ä»Šå¤©çš„æ—¥æœŸæ˜¯å¦å·²å­˜åœ¨äºREADMEä¸­
        date_pattern = f"## {re.escape(date_str)}"
        
        if re.search(date_pattern, content):
            # æ›¿æ¢ä»Šå¤©ç°æœ‰çš„æ¡ç›®
            # ä½¿ç”¨æ›´ç²¾ç¡®çš„æ­£åˆ™è¡¨è¾¾å¼æ¥åŒ¹é…æ•´ä¸ªæ—¥æœŸsection
            pattern = f"(## {re.escape(date_str)}.*?)(?=\n## \\d{{4}}-\\d{{2}}-\\d{{2}}|\n# |$)"
            
            # æ„å»ºæ›¿æ¢å†…å®¹
            replacement_lines = []
            for path in all_today_reports:
                timestamp = extract_timestamp(path)
                formatted_time = f"{timestamp[:2]}:{timestamp[2:4]}:{timestamp[4:6]}"
                filename = os.path.basename(path)
                
                # æå–ä»“åº“å
                repo_name = filename
                timestamp_pattern = r'^\d{6}_'
                if re.match(timestamp_pattern, filename):
                    repo_name = filename[7:]  # å»æ‰æ—¶é—´æˆ³å‰ç¼€
                if repo_name.endswith('.md'):
                    repo_name = repo_name[:-3]  # å»æ‰.mdåç¼€
                
                replacement_lines.append(f"- [{formatted_time}] [{repo_name}]({path})")
            
            replacement = f"## {date_str}\n\n" + "\n".join(replacement_lines) + "\n"
            
            content = re.sub(pattern, replacement, content, flags=re.DOTALL)
        else:
            # åœ¨READMEä¸­æ·»åŠ æ–°æ¡ç›®
            # æ‰¾åˆ°åˆé€‚çš„æ’å…¥ä½ç½®ï¼ˆæŒ‰æ—¥æœŸé™åºï¼‰
            lines = content.split('\n')
            insert_index = len(lines)
            
            # å¯»æ‰¾æ’å…¥ä½ç½®ï¼šæ‰¾åˆ°ç¬¬ä¸€ä¸ªæ¯”ä»Šå¤©æ—¥æœŸå°çš„æ—¥æœŸ
            for i, line in enumerate(lines):
                date_match = re.match(r'^## (\d{4}-\d{2}-\d{2})', line)
                if date_match:
                    existing_date = date_match.group(1)
                    if existing_date < date_str:
                        insert_index = i
                        break
            
            # åœ¨æ‰¾åˆ°çš„ä½ç½®æ’å…¥æ–°æ¡ç›®
            new_entry_lines = new_entry.strip().split('\n')
            for j, new_line in enumerate(reversed(new_entry_lines)):
                lines.insert(insert_index, new_line)
            
            content = '\n'.join(lines)
        
        # å†™å…¥æ›´æ–°åçš„README
        with open(readme_path, 'w', encoding='utf-8') as f:
            f.write(content)
        
        print(f"README.md updated with {len(all_today_reports)} report links (sorted by time)")
        return True
        
    except Exception as e:
        print(f"æ›´æ–° README.md æ—¶å‘ç”Ÿå¼‚å¸¸: {str(e)}")
        return False

def process_repository(repo):
    """Process a single repository"""
    print(f"\nProcessing repository: {repo}")
    
    # æ£€æŸ¥å¿…è¦çš„ç¯å¢ƒå˜é‡
    if not github_token:
        print(f"GitHub token not found, skipping {repo}")
        return None
    
    if not api_key:
        print(f"DeepSeek API key not found, skipping {repo}")
        return None
    
    commits = get_commits(repo, since_date, today)
    
    if not commits:
        if is_manual:
            print(f"No commits found for {repo}, generating test report for manual trigger")
            commits_text = f"No commits found in the selected period ({since_date} to {today}). This is a test report for manual trigger."
        else:
            print(f"No commits found for {repo} in the selected period.")
            return None
    else:
        commit_messages = process_commits(commits, repo)
        if not commit_messages:
            print(f"No valid commit messages processed for {repo}")
            return None
        commits_text = "\n\n".join(commit_messages)
    
    print(f"Generating report for {repo}...")
    report_content = generate_report(commits_text, repo)
    
    # Save report to file
    repo_name = repo.split('/')[-1]
    return save_report(report_content, repo_name)

# ä¸»æ‰§è¡Œé€»è¾‘
def main():
    print("Starting report generation...")
    
    # æ£€æŸ¥ç¯å¢ƒå˜é‡
    missing_vars = []
    if not github_token:
        missing_vars.append('GITHUB_TOKEN')
    if not api_key:
        missing_vars.append('DEEPSEEK_API_KEY')
    
    if missing_vars:
        print(f"Missing required environment variables: {', '.join(missing_vars)}")
        return
    
    # Process additional repositories
    additional_reports = []
    for repo in additional_repos:
        report_path = process_repository(repo)
        if report_path:
            additional_reports.append(report_path)

    print("\nReport generation complete!")
        
    if additional_reports:
        print("Generated repository reports:")
        for report in additional_reports:
            print(f"- {report}")
        
        # Update README.md with links to generated reports
        print("\nUpdating README.md...")
        if update_readme(additional_reports):
            print("README.md updated successfully!")
        else:
            print("Failed to update README.md")
    else:
        print("No repository reports generated")

if __name__ == "__main__":
    main()
